dataset_name: 'ogbn-mag'
task: 'NodeClassification'
metrics: ['acc','f1-micro','f1-macro']
track_metric: 'acc'

DownStream:
  saved_embeddings: False
  using_features: True
  use_spectral: False
  random: False
  K: 16
  training:
    epochs: 500
    num_layers: 3
    dropout: 0.0
    lr: 0.01
    hidden_channels: 256
    batchnorm: False
    weight_decay: 0

Node2Vec:
  training:
    embedding_dim: 128
    walk_length: 80
    context_size: 20
    walks_per_node: 10
    epochs: 3
    lr: 0.01
    batch_size: 256
    num_negative_samples: 1
    sparse: True
    num_workers: 4

GNN:
  model: 'GraphSage'
  extra_info: False
  training:
    hidden_channels: 256
    num_layers: 2
    dropout: 0.5
    lr: 0.01
    epochs: 100
    batchnorm: False
    weight_decay: 0


Shallow:
  training:
    lr: 0.1
    epochs: 50
    init_beta: 0.0
    embedding_dim: 2
    init: 'laplacian'
    decode_type: 'dist'
    train_batch: False
    batch_size: 65536
    weight_decay: 0


combined:
  type: 'comb1'
  comb1:
    training:
      shallow_lr: 0.1
      init_beta: 0.0
      embedding_dim: 64
      init: 'random'
      decode_type: 'dist'

      deep_model: 'GraphSage'
      deep_hidden_channels: 256
      deep_lr: 0.005
      deep_out_dim: 256
      deep_num_layers: 3
      deep_dropout: 0.1
      deep_decode: 'dist'
      gamma: 0.0

      MLP_HIDDEN: 256
      MLP_NUM_LAYERS: 3
      MLP_DROPOUT: 0.5
      MLP_LR: 0.01
      MLP_EPOCHS: 1


      balance: False
      warm_start: 1
      joint_train: 1
      shallow_lr_joint: 0.1
      deep_lr_joint: 0.001
      lambda_lr: 0.01
      lambda_: 1.0
      batch_size: 65536
      direction: 'shallow_first'
      shallow_frozen_epochs: 0
      deep_frozen_epochs: 0

  comb2:
    training:
      shallow_lr: 0.1
      init_beta: 0.0
      embedding_dim: 64
      init: 'random'
      decode_type: 'dist'
      SHALLOW_WARM_START: 1
      SHALLOW_TRAIN_BATCH: False
      SHALLOW_WARM_BATCH_SIZE: 65536


      deep_model: 'GraphSage'
      deep_hidden_channels: 256
      deep_lr: 0.001
      deep_out_dim: 256
      deep_num_layers: 3
      deep_dropout: 0.0

      MLP_HIDDEN: 256
      MLP_NUM_LAYERS: 3
      MLP_DROPOUT: 0.5
      MLP_LR: 0.01
      MLP_EPOCHS: 1
      APPLY_BATCHNORM: True


      epochs: 1
      batch_size: 65536
      direction: 'shallow_first'
      shallow_frozen_epochs: 0
      deep_frozen_epochs: 0
